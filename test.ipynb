{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a53804a",
   "metadata": {},
   "source": [
    "# Basic working of Google LLM in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8d785d-86a8-4f3e-93be-0aad2cc98dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-community\n",
    "!pip install langchain-google-genai\n",
    "!pip install InstructorEmbedding\n",
    "!pip install torchvision \n",
    "!pip install sentence-transformers==2.2.2\n",
    "!pip install faiss-cpu\n",
    "!pip install urllib3==1.26.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9a2cda-8541-4e3b-be13-7344bc1a4396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "        model='gemini-1.5-pro',\n",
    "        google_api_key='your api key here', # get this free api key from https://makersuite.google.com/\n",
    "        temperature=0.5\n",
    ")\n",
    "\n",
    "poem = llm.invoke(\"Write a 4 line poem of my love for samosa\")\n",
    "print(poem.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394ece6a",
   "metadata": {},
   "source": [
    "\n",
    "# Now let's load data from Codebasics FAQ csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95f118-e099-4338-8a23-6c59b6ab1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='codebasics_faqs.csv', encoding=\"ISO-8859-1\", source_column='prompt')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55309a",
   "metadata": {},
   "source": [
    "# Hugging Face Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7298b6de-9d1f-48b1-9660-8f9dd2de4f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ironfish/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Users/ironfish/Library/Python/3.9/lib/python/site-packages/sentence_transformers/models/Dense.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(input_path, 'pytorch_model.bin'), map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name=\"hkunlp/instructor-large\",\n",
    "    query_instruction=\"Represent the query for retrieval: \"\n",
    ")\n",
    "\n",
    "vectordb = FAISS.from_documents(documents=docs, embedding=instructor_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa681f",
   "metadata": {},
   "source": [
    "# Vector store using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "884461ec-81c2-4d60-8c0c-24a72f62b48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'I have never done programming and belong to a non-technical background. Can I take this course?', 'row': 24}, page_content='prompt: I have never done programming and belong to a non-technical background. Can I take this course?\\nresponse: Yes, this is the perfect course for anyone who has never done coding and wants to build a career in the IT/Data Analytics industry or just wants to perform better in their current job or business using data.'),\n",
       " Document(metadata={'source': 'Is there any prerequisite for taking this bootcamp ?', 'row': 2}, page_content='prompt: Is there any prerequisite for taking this bootcamp ?\\nresponse: Our bootcamp is specifically designed for beginners with no prior experience in this field. The only prerequisite is that you need to have a functional laptop with at least 4GB ram, an internet connection, and a thrill to learn data analysis.'),\n",
       " Document(metadata={'source': 'I have never done programming in my life. Can I take this bootcamp?', 'row': 0}, page_content='prompt: I have never done programming in my life. Can I take this bootcamp?\\nresponse: Yes, this is the perfect bootcamp for anyone who has never done coding and wants to build a career in the IT/Data Analytics industry or just wants to perform better in your current job or business using data.'),\n",
       " Document(metadata={'source': 'I have zero knowledge of Excel and belong to a non-technical\\n background. Can I take this course?', 'row': 16}, page_content='prompt: I have zero knowledge of Excel and belong to a non-technical\\n background. Can I take this course?\\nresponse: Yes, this is the perfect course for anyone who has never worked on excel and wants to build a career in the IT/Data Analytics industry or just wants to perform better in their current job or business using data.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever(score_threshold = 0.7)\n",
    "rdocs = retriever.get_relevant_documents(\"do you have javascript course\")\n",
    "rdocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f6ba5",
   "metadata": {},
   "source": [
    "As you can see above, the retriever that was created using FAISS and hugging face embedding is now capable of pulling relavant documents from our original CSV file knowledge store. This is very powerful and it will help us further in our project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d4970b",
   "metadata": {},
   "source": [
    "# Create RetrievalQA chain along with prompt template üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f468d704-69eb-4bb1-abb6-ec4041e4a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on the following pieces of context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context.\n",
    "If you can't find the answer in the context, please kindly state \"I don't know.\"\n",
    "\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d720d158-d07f-442d-85c2-8e1c533ca125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    input_key=\"query\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs = {\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are all set üëçüèº Let's ask some questions now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4d5cb005-4729-4ca3-81f6-30b2702660dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Do you have a plan of lauching blockchain course in the future?',\n",
       " 'result': \"I don't know. \\n\",\n",
       " 'source_documents': [Document(metadata={'source': 'Will the course be upgraded when there are new features in Power BI?', 'row': 27}, page_content='prompt: Will the course be upgraded when there are new features in Power BI?\\nresponse: Yes, the course will be upgraded periodically based on the new features in Power BI, and learners who have already bought this course will have free access to the upgrades.'),\n",
       "  Document(metadata={'source': 'Is there any prerequisite for taking this course?', 'row': 35}, page_content='prompt: Is there any prerequisite for taking this course?\\nresponse: The only prerequisite is that you need to have a functional laptop with at least 4GB ram, internet connection and a thrill to learn data analysis.'),\n",
       "  Document(metadata={'source': 'Is there any prerequisite for taking this bootcamp ?', 'row': 2}, page_content='prompt: Is there any prerequisite for taking this bootcamp ?\\nresponse: Our bootcamp is specifically designed for beginners with no prior experience in this field. The only prerequisite is that you need to have a functional laptop with at least 4GB ram, an internet connection, and a thrill to learn data analysis.'),\n",
       "  Document(metadata={'source': 'I already know basic Power BI, what benefit do I get by taking this course?', 'row': 37}, page_content='prompt: I already know basic Power BI, what benefit do I get by taking this course?\\nresponse: This course is taught through a true end-to-end project in a Consumer goods company involving all the steps mimicking the real business environment, so you will learn how to execute end-to-end projects Power BI projects successfully along with the business fundamentals. You will learn a lot of extra things such as Project management tools, effective communication techniques & organizational nuances.')]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Do you have a plan of lauching blockchain course in the future?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe1ff05-f48d-492f-a18a-9d88efd6bf79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
